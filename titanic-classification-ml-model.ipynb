{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-12T22:05:17.324916Z","iopub.execute_input":"2022-06-12T22:05:17.325337Z","iopub.status.idle":"2022-06-12T22:05:17.339109Z","shell.execute_reply.started":"2022-06-12T22:05:17.325302Z","shell.execute_reply":"2022-06-12T22:05:17.338226Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:34:32.899216Z","iopub.execute_input":"2022-06-12T20:34:32.900082Z","iopub.status.idle":"2022-06-12T20:34:32.919928Z","shell.execute_reply.started":"2022-06-12T20:34:32.900046Z","shell.execute_reply":"2022-06-12T20:34:32.919184Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"data_test = pd.read_csv('/kaggle/input/titanic/test.csv')\ndata_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:34:35.370678Z","iopub.execute_input":"2022-06-12T20:34:35.371071Z","iopub.status.idle":"2022-06-12T20:34:35.389211Z","shell.execute_reply.started":"2022-06-12T20:34:35.371041Z","shell.execute_reply":"2022-06-12T20:34:35.388468Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"data_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:34:37.483423Z","iopub.execute_input":"2022-06-12T20:34:37.483843Z","iopub.status.idle":"2022-06-12T20:34:37.489863Z","shell.execute_reply.started":"2022-06-12T20:34:37.483787Z","shell.execute_reply":"2022-06-12T20:34:37.489071Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"data_train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:35:30.122346Z","iopub.execute_input":"2022-06-12T20:35:30.122784Z","iopub.status.idle":"2022-06-12T20:35:30.158927Z","shell.execute_reply.started":"2022-06-12T20:35:30.122747Z","shell.execute_reply":"2022-06-12T20:35:30.157895Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"This is our dataset description and its looking fine, Now let's just find the null values present in our dataset.","metadata":{}},{"cell_type":"code","source":"data_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:35:37.675616Z","iopub.execute_input":"2022-06-12T20:35:37.676591Z","iopub.status.idle":"2022-06-12T20:35:37.686369Z","shell.execute_reply.started":"2022-06-12T20:35:37.676550Z","shell.execute_reply":"2022-06-12T20:35:37.685537Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"Found null values in Age, Cabin, Embarked columns.","metadata":{}},{"cell_type":"code","source":"data_train['Age'] = data_train['Age'].fillna(data_train['Age'].median())\ndata_train['Embarked'] = data_train['Embarked'].fillna(data_train['Embarked'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:35:59.556279Z","iopub.execute_input":"2022-06-12T20:35:59.557128Z","iopub.status.idle":"2022-06-12T20:35:59.567755Z","shell.execute_reply.started":"2022-06-12T20:35:59.557083Z","shell.execute_reply":"2022-06-12T20:35:59.566781Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"data_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:36:03.999021Z","iopub.execute_input":"2022-06-12T20:36:03.999426Z","iopub.status.idle":"2022-06-12T20:36:04.011602Z","shell.execute_reply.started":"2022-06-12T20:36:03.999393Z","shell.execute_reply":"2022-06-12T20:36:04.011068Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Filled all the missing values using fillna and with the help of median() and mode(). And I am not filling the missing values in cabin as we are going to drop the cabin column.","metadata":{}},{"cell_type":"code","source":"data_train = data_train.drop(columns = ['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)\ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:36:16.709760Z","iopub.execute_input":"2022-06-12T20:36:16.710390Z","iopub.status.idle":"2022-06-12T20:36:16.725267Z","shell.execute_reply.started":"2022-06-12T20:36:16.710361Z","shell.execute_reply":"2022-06-12T20:36:16.724491Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Dropped all the unwanted columns.","metadata":{}},{"cell_type":"code","source":"data_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:36:23.926959Z","iopub.execute_input":"2022-06-12T20:36:23.927365Z","iopub.status.idle":"2022-06-12T20:36:23.933404Z","shell.execute_reply.started":"2022-06-12T20:36:23.927330Z","shell.execute_reply":"2022-06-12T20:36:23.932524Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Now, the shape of the dataset is (891,8)","metadata":{}},{"cell_type":"code","source":"data_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:36:29.344707Z","iopub.execute_input":"2022-06-12T20:36:29.345452Z","iopub.status.idle":"2022-06-12T20:36:29.358310Z","shell.execute_reply.started":"2022-06-12T20:36:29.345418Z","shell.execute_reply":"2022-06-12T20:36:29.357121Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"There are still problem in our dataset as there is also object value present in dataset, which is going to create a problem for the machine as it accepts only int/float values.","metadata":{}},{"cell_type":"code","source":"lab = LabelEncoder()\nsex = lab.fit_transform(data_train['Sex'])\nembarked = lab.fit_transform(data_train['Embarked'])","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:38:54.464836Z","iopub.execute_input":"2022-06-12T20:38:54.465230Z","iopub.status.idle":"2022-06-12T20:38:54.471007Z","shell.execute_reply.started":"2022-06-12T20:38:54.465198Z","shell.execute_reply":"2022-06-12T20:38:54.470209Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"data_train['Sex'] = sex\ndata_train['Embarked'] = embarked","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:39:14.752897Z","iopub.execute_input":"2022-06-12T20:39:14.753312Z","iopub.status.idle":"2022-06-12T20:39:14.759497Z","shell.execute_reply.started":"2022-06-12T20:39:14.753276Z","shell.execute_reply":"2022-06-12T20:39:14.758103Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"data_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:39:21.897022Z","iopub.execute_input":"2022-06-12T20:39:21.897430Z","iopub.status.idle":"2022-06-12T20:39:21.911433Z","shell.execute_reply.started":"2022-06-12T20:39:21.897396Z","shell.execute_reply":"2022-06-12T20:39:21.910702Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"* Encoded all the object data to integer data using LabelEncoder()\n","metadata":{}},{"cell_type":"markdown","source":"Lets, check it again.","metadata":{}},{"cell_type":"code","source":"data_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:41:20.567055Z","iopub.execute_input":"2022-06-12T20:41:20.567578Z","iopub.status.idle":"2022-06-12T20:41:20.583908Z","shell.execute_reply.started":"2022-06-12T20:41:20.567531Z","shell.execute_reply":"2022-06-12T20:41:20.582944Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"Encoded all the object values.","metadata":{}},{"cell_type":"markdown","source":"# Now our dataset is clean and ready for further process","metadata":{}},{"cell_type":"markdown","source":"Checking the balance of the dataset based on our label i.e. Survived","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = 'Survived', data = data_train)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:54:28.952840Z","iopub.execute_input":"2022-06-12T20:54:28.953177Z","iopub.status.idle":"2022-06-12T20:54:29.140353Z","shell.execute_reply.started":"2022-06-12T20:54:28.953149Z","shell.execute_reply":"2022-06-12T20:54:29.139624Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"It is clear that the dataset is Balanced based on label","metadata":{}},{"cell_type":"markdown","source":"Now, checking the multicollinearity using heatplot map","metadata":{}},{"cell_type":"code","source":"data_corr = data_train.corr()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:01:02.817278Z","iopub.execute_input":"2022-06-12T21:01:02.817700Z","iopub.status.idle":"2022-06-12T21:01:02.823158Z","shell.execute_reply.started":"2022-06-12T21:01:02.817666Z","shell.execute_reply":"2022-06-12T21:01:02.822254Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,10))\nsns.heatmap(data_corr,annot = True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:03:06.589874Z","iopub.execute_input":"2022-06-12T21:03:06.590209Z","iopub.status.idle":"2022-06-12T21:03:07.005718Z","shell.execute_reply.started":"2022-06-12T21:03:06.590184Z","shell.execute_reply":"2022-06-12T21:03:07.004616Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"There is no multocollinearity between columns","metadata":{}},{"cell_type":"markdown","source":"* Seperating the label and features","metadata":{}},{"cell_type":"code","source":"x_feature = data_train.drop(columns = ['Survived'])\nx_label = data_train['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:18:02.704142Z","iopub.execute_input":"2022-06-12T21:18:02.704497Z","iopub.status.idle":"2022-06-12T21:18:02.709651Z","shell.execute_reply.started":"2022-06-12T21:18:02.704469Z","shell.execute_reply":"2022-06-12T21:18:02.708684Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"Now, using the StandardScaler() on the Features","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nx_scaled = scaler.fit_transform(x_feature)\nx_scaled","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:20:43.120458Z","iopub.execute_input":"2022-06-12T21:20:43.121131Z","iopub.status.idle":"2022-06-12T21:20:43.133597Z","shell.execute_reply.started":"2022-06-12T21:20:43.121090Z","shell.execute_reply":"2022-06-12T21:20:43.132407Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"# - Training the model","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x_feature, x_label, test_size = 0.25, random_state = 9)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:25:24.909281Z","iopub.execute_input":"2022-06-12T21:25:24.909725Z","iopub.status.idle":"2022-06-12T21:25:24.917502Z","shell.execute_reply.started":"2022-06-12T21:25:24.909689Z","shell.execute_reply":"2022-06-12T21:25:24.916841Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"* Selecting the best Model for our dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve,roc_auc_score\nfrom sklearn.metrics import plot_roc_curve","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:27:59.098163Z","iopub.execute_input":"2022-06-12T21:27:59.098620Z","iopub.status.idle":"2022-06-12T21:27:59.287506Z","shell.execute_reply.started":"2022-06-12T21:27:59.098580Z","shell.execute_reply":"2022-06-12T21:27:59.286321Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression()\nkn = KNeighborsClassifier()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:28:14.010382Z","iopub.execute_input":"2022-06-12T21:28:14.010733Z","iopub.status.idle":"2022-06-12T21:28:14.016239Z","shell.execute_reply.started":"2022-06-12T21:28:14.010705Z","shell.execute_reply":"2022-06-12T21:28:14.015232Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"*Defining all the models*","metadata":{}},{"cell_type":"code","source":"lr.fit(x_train,y_train)\nkn.fit(x_train,y_train)\ndt.fit(x_train,y_train)\nrf.fit(x_train,y_train)\n\nprint(\"ALL MODELS ARE TRAINED\")","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:28:28.168206Z","iopub.execute_input":"2022-06-12T21:28:28.168639Z","iopub.status.idle":"2022-06-12T21:28:28.358210Z","shell.execute_reply.started":"2022-06-12T21:28:28.168601Z","shell.execute_reply":"2022-06-12T21:28:28.357120Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"print('Logistic Regression Score : ',lr.score(x_train,y_train))\nprint('KNearest Neighbor Score : ',kn.score(x_train,y_train))\nprint('Decision Tree Score : ',dt.score(x_train,y_train))\nprint('Random Forest Score : ',rf.score(x_train,y_train))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:33:37.845724Z","iopub.execute_input":"2022-06-12T21:33:37.846701Z","iopub.status.idle":"2022-06-12T21:33:37.914880Z","shell.execute_reply.started":"2022-06-12T21:33:37.846658Z","shell.execute_reply":"2022-06-12T21:33:37.913736Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"***This is the score of particular model on training***","metadata":{}},{"cell_type":"code","source":"disp = plot_roc_curve(dt, x_train, y_train)\nplot_roc_curve(kn,x_train,y_train, ax = disp.ax_)\nplot_roc_curve(lr,x_train,y_train, ax = disp.ax_)\nplot_roc_curve(rf,x_train,y_train, ax = disp.ax_)\nplt.legend(prop = {'size': 10}, loc = 'lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:29:13.134755Z","iopub.execute_input":"2022-06-12T21:29:13.135201Z","iopub.status.idle":"2022-06-12T21:29:13.354911Z","shell.execute_reply.started":"2022-06-12T21:29:13.135167Z","shell.execute_reply":"2022-06-12T21:29:13.353773Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"*On training this is the score for particular model and we find that Decision Tree and Random Forest is giving best score based on training data.*","metadata":{}},{"cell_type":"code","source":"print('Logistic Regression Score : ',lr.score(x_test,y_test))\nprint('KNearest Neighbor Score : ',kn.score(x_test,y_test))\nprint('Decision Tree Score : ',dt.score(x_test,y_test))\nprint('Random Forest Score : ',rf.score(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:59:14.865736Z","iopub.execute_input":"2022-06-12T21:59:14.866602Z","iopub.status.idle":"2022-06-12T21:59:14.908417Z","shell.execute_reply.started":"2022-06-12T21:59:14.866556Z","shell.execute_reply":"2022-06-12T21:59:14.907564Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"***This is the score of particular model on testing***","metadata":{}},{"cell_type":"code","source":"disp = plot_roc_curve(dt, x_test, y_test)\nplot_roc_curve(kn,x_test,y_test, ax = disp.ax_)\nplot_roc_curve(lr,x_test,y_test, ax = disp.ax_)\nplot_roc_curve(rf,x_test,y_test, ax = disp.ax_)\nplt.legend(prop = {'size': 10}, loc = 'lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T21:29:33.234736Z","iopub.execute_input":"2022-06-12T21:29:33.235179Z","iopub.status.idle":"2022-06-12T21:29:33.426733Z","shell.execute_reply.started":"2022-06-12T21:29:33.235143Z","shell.execute_reply":"2022-06-12T21:29:33.425568Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"*On testing score, it is clear that  Random Forest and Logistic Regression score is the top 2 score among all. And can see the difference in decision tree score of testing and training.*","metadata":{}},{"cell_type":"markdown","source":"**- Model Instantiating & Trainning**","metadata":{}},{"cell_type":"code","source":"#rf = RandomForestClassifier()\nrf.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:08:40.196555Z","iopub.execute_input":"2022-06-12T22:08:40.197232Z","iopub.status.idle":"2022-06-12T22:08:40.419556Z","shell.execute_reply.started":"2022-06-12T22:08:40.197189Z","shell.execute_reply":"2022-06-12T22:08:40.418738Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"Random Forest Classifier model is Instantiated","metadata":{}},{"cell_type":"code","source":"y_pred = rf.predict(x_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:07:10.265505Z","iopub.execute_input":"2022-06-12T22:07:10.266239Z","iopub.status.idle":"2022-06-12T22:07:10.287715Z","shell.execute_reply.started":"2022-06-12T22:07:10.266203Z","shell.execute_reply":"2022-06-12T22:07:10.287058Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"Prediction using Random Forest Classifier","metadata":{}},{"cell_type":"markdown","source":"* Now, Creating a confusion matrix","metadata":{}},{"cell_type":"code","source":"cfm = confusion_matrix(y_test, y_pred)\ncfm","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:10:10.091127Z","iopub.execute_input":"2022-06-12T22:10:10.091576Z","iopub.status.idle":"2022-06-12T22:10:10.101304Z","shell.execute_reply.started":"2022-06-12T22:10:10.091536Z","shell.execute_reply":"2022-06-12T22:10:10.100734Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"1. False Positive : 18\n2. False Negative : 29","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, y_pred, digits = 2))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T22:10:26.252233Z","iopub.execute_input":"2022-06-12T22:10:26.253026Z","iopub.status.idle":"2022-06-12T22:10:26.262842Z","shell.execute_reply.started":"2022-06-12T22:10:26.252992Z","shell.execute_reply":"2022-06-12T22:10:26.262076Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"**So, This is the Classification Report and according to this the accuracy of our model is 79%**","metadata":{}}]}